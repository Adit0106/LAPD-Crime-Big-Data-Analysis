{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/Users/adit0106/opt/anaconda3/lib/python3.9'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/Users/adit0106/opt/anaconda3/lib/python3.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jn9cadJnF-IQ",
    "outputId": "869231f2-de8a-4ee8-c8eb-20beda15c98e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/adit0106/opt/anaconda3/lib/python3.9/site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/adit0106/opt/anaconda3/lib/python3.9/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcPncvD6GA_T",
    "outputId": "92c2435a-cbb3-475c-c358-3e91f0000105"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3GdN-qVmGC5J"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import to_date, col, regexp_replace, concat_ws, lit, coalesce, when\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "K0rIeXtnGEH9"
   },
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "spark = SparkSession.builder.appName(\"tableau_data\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZw-LQKNGHVa",
    "outputId": "2ae017eb-40a8-4bcb-f1b9-e55cb82b9749",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+------+---------+---------+---------+-----+--------------------+--------------+-------+-------+--------------------+--------+--------------------+--------------------+------+------------+--------+---------+---------------+\n",
      "|  DateRptd|   DateOcc|TimeOcc|AreaCd| AreaName|RptDistNo|CrimeType|CrmCd|           CrmCdDesc|       Mocodes|VictAge|VictSex|         VictDescent|PremisCd|          PremisDesc|              Weapon|Status|  StatusDesc|Latitude|Longitude|        Address|\n",
      "+----------+----------+-------+------+---------+---------+---------+-----+--------------------+--------------+-------+-------+--------------------+--------+--------------------+--------------------+------+------------+--------+---------+---------------+\n",
      "|2020-01-08|2020-01-08|   2230|     3|Southwest|      377|        2|  624|BATTERY - SIMPLE ...|     0444 0913|     36|      F|               Black|     501|SINGLE FAMILY DWE...|STRONG-ARM (HANDS...|    AO| Adult Other| 34.0141|-118.2978|1100 W 39TH PL |\n",
      "|2020-01-02|2020-01-01|    330|     1|  Central|      163|        2|  624|BATTERY - SIMPLE ...|0416 1822 1414|     25|      M|Hispanic/Latin/Me...|     102|            SIDEWALK|UNKNOWN WEAPON/OT...|    IC| Invest Cont| 34.0459|-118.2545| 700 S HILL ST |\n",
      "|2020-04-14|2020-02-13|   1200|     1|  Central|      155|        2|  845|SEX OFFENDER REGI...|          1501|      0|      X|                None|     726|     POLICE FACILITY|      NO WEAPON INFO|    AA|Adult Arrest| 34.0448|-118.2474|  200 E 6TH ST |\n",
      "+----------+----------+-------+------+---------+---------+---------+-----+--------------------+--------------+-------+-------+--------------------+--------+--------------------+--------------------+------+------------+--------+---------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# # VAIDEHI path to cleaned dataset\n",
    "# file_path = \"/content/gdrive/MyDrive/FALL 23/CS777/Term Project/Cleaned_Crime.csv\"\n",
    "\n",
    "# ADITYA pah to cleaned dataset\n",
    "# file_path = \"/content/gdrive/MyDrive/BU/SEM 3/CS777/CS 777 Final Project/Cleaned_Crime.csv\"\n",
    "file_path = \"/Users/adit0106/Desktop/CS777 Final Project/Cleaned_Crime.csv\"\n",
    "# SARTHAK path to cleaned dataset\n",
    "# file_path =\n",
    "\n",
    "df_spark = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "df_spark.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmB6bquQGbby"
   },
   "source": [
    "## filter for victim demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6RaLSStGWJG",
    "outputId": "aad386ec-4f47-4b7e-eb1b-4095fc410a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+------+-----------+---------+---------+-----+--------------------+--------------+-------+-------+--------------------+--------+--------------------+--------------------+------+-----------+--------+---------+----------------+\n",
      "|  DateRptd|   DateOcc|TimeOcc|AreaCd|   AreaName|RptDistNo|CrimeType|CrmCd|           CrmCdDesc|       Mocodes|VictAge|VictSex|         VictDescent|PremisCd|          PremisDesc|              Weapon|Status| StatusDesc|Latitude|Longitude|         Address|\n",
      "+----------+----------+-------+------+-----------+---------+---------+-----+--------------------+--------------+-------+-------+--------------------+--------+--------------------+--------------------+------+-----------+--------+---------+----------------+\n",
      "|2020-01-08|2020-01-08|   2230|     3|  Southwest|      377|        2|  624|BATTERY - SIMPLE ...|     0444 0913|     36|      F|               Black|     501|SINGLE FAMILY DWE...|STRONG-ARM (HANDS...|    AO|Adult Other| 34.0141|-118.2978| 1100 W 39TH PL |\n",
      "|2020-01-02|2020-01-01|    330|     1|    Central|      163|        2|  624|BATTERY - SIMPLE ...|0416 1822 1414|     25|      M|Hispanic/Latin/Me...|     102|            SIDEWALK|UNKNOWN WEAPON/OT...|    IC|Invest Cont| 34.0459|-118.2545|  700 S HILL ST |\n",
      "|2020-01-01|2020-01-01|   1730|    15|N Hollywood|     1543|        2|  745|VANDALISM - MISDE...|     0329 1402|     76|      F|               White|     502|MULTI-UNIT DWELLI...|      NO WEAPON INFO|    IC|Invest Cont| 34.1685|-118.4019|5400 CORTEEN PL |\n",
      "+----------+----------+-------+------+-----------+---------+---------+-----+--------------------+--------------+-------+-------+--------------------+--------+--------------------+--------------------+------+-----------+--------+---------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace 'VictAge', 'VictSex', 'VictDescent' with your actual column names\n",
    "df_spark = df_spark.filter(\n",
    "    (col(\"VictAge\") > 0) &\n",
    "    (col(\"VictSex\") != \"NULL\") &\n",
    "    (col(\"VictDescent\").isin([\"None\", \"NULL\"]) == False)\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "df_spark.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_CGb-ciHHGK"
   },
   "source": [
    "## adding time-of-day column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MsljJXSiGeiy",
    "outputId": "d3f2e03b-6ab5-47d1-f6f5-e8445cad7b21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+------+-----------+---------+---------+-----+--------------------+--------------------+-------+-------+--------------------+--------+--------------------+--------------------+------+------------+--------+---------+--------------------+---------+\n",
      "|  DateRptd|   DateOcc|TimeOcc|AreaCd|   AreaName|RptDistNo|CrimeType|CrmCd|           CrmCdDesc|             Mocodes|VictAge|VictSex|         VictDescent|PremisCd|          PremisDesc|              Weapon|Status|  StatusDesc|Latitude|Longitude|             Address|TimeOfDay|\n",
      "+----------+----------+-------+------+-----------+---------+---------+-----+--------------------+--------------------+-------+-------+--------------------+--------+--------------------+--------------------+------+------------+--------+---------+--------------------+---------+\n",
      "|2020-01-08|2020-01-08|   2230|     3|  Southwest|      377|        2|  624|BATTERY - SIMPLE ...|           0444 0913|     36|      F|               Black|     501|SINGLE FAMILY DWE...|STRONG-ARM (HANDS...|    AO| Adult Other| 34.0141|-118.2978|     1100 W 39TH PL |    Night|\n",
      "|2020-01-02|2020-01-01|    330|     1|    Central|      163|        2|  624|BATTERY - SIMPLE ...|      0416 1822 1414|     25|      M|Hispanic/Latin/Me...|     102|            SIDEWALK|UNKNOWN WEAPON/OT...|    IC| Invest Cont| 34.0459|-118.2545|      700 S HILL ST |    Night|\n",
      "|2020-01-01|2020-01-01|   1730|    15|N Hollywood|     1543|        2|  745|VANDALISM - MISDE...|           0329 1402|     76|      F|               White|     502|MULTI-UNIT DWELLI...|      NO WEAPON INFO|    IC| Invest Cont| 34.1685|-118.4019|    5400 CORTEEN PL |  Evening|\n",
      "|2020-01-02|2020-01-01|     30|     1|    Central|      163|        1|  121|      RAPE, FORCIBLE| 0413 1822 1262 1415|     25|      F|Hispanic/Latin/Me...|     735|NIGHT CLUB (OPEN ...|UNKNOWN WEAPON/OT...|    IC| Invest Cont| 34.0452|-118.2534|     700 S BROADWAY |    Night|\n",
      "|2020-01-02|2020-01-02|   1315|     1|    Central|      161|        1|  442|SHOPLIFTING - PET...| 1402 2004 0344 0387|     23|      M|Hispanic/Latin/Me...|     404|    DEPARTMENT STORE|      NO WEAPON INFO|    IC| Invest Cont| 34.0483|-118.2631|  700 S FIGUEROA ST |Afternoon|\n",
      "|2020-01-04|2020-01-04|    200|     1|    Central|      101|        1|  341|THEFT-GRAND ($950...|      1822 0344 1402|     23|      M|               Black|     502|MULTI-UNIT DWELLI...|      NO WEAPON INFO|    IC| Invest Cont| 34.0677|-118.2398|     700 BERNARD ST |    Night|\n",
      "|2020-01-04|2020-01-04|   2200|     1|    Central|      192|        1|  330|BURGLARY FROM VEH...| 1822 1414 0344 1307|     29|      M|         Other Asian|     101|              STREET|  ROCK/THROWN OBJECT|    IC| Invest Cont| 34.0359|-118.2648|          15TH OLIVE|    Night|\n",
      "|2020-01-05|2020-01-05|    955|     1|    Central|      111|        2|  930|CRIMINAL THREATS ...|           0421 0906|     35|      M|               Other|     108|         PARKING LOT|       VERBAL THREAT|    IC| Invest Cont| 34.0615|-118.2412|   800 N ALAMEDA ST |  Morning|\n",
      "|2020-01-05|2020-01-05|   1355|     1|    Central|      162|        1|  341|THEFT-GRAND ($950...|      1822 0344 2032|     41|      M|         Other Asian|     503|               HOTEL|      NO WEAPON INFO|    AA|Adult Arrest| 34.0452|-118.2569|     800 S OLIVE ST |Afternoon|\n",
      "|2020-01-08|2020-01-08|   1805|     1|    Central|      128|        1|  442|SHOPLIFTING - PET...| 0325 1402 0344 1822|     24|      F|Hispanic/Latin/Me...|     252|COFFEE SHOP (STAR...|      NO WEAPON INFO|    IC| Invest Cont| 34.0515|-118.2424|100 S LOS ANGELES...|  Evening|\n",
      "|2021-11-26|2020-11-30|    730|    19|    Mission|     1916|        2|  626|INTIMATE PARTNER ...|      2000 1814 0416|     24|      F|Hispanic/Latin/Me...|     501|SINGLE FAMILY DWE...|STRONG-ARM (HANDS...|    IC| Invest Cont| 34.3055|-118.4439|      14200 BERG ST |  Morning|\n",
      "|2020-11-29|2020-11-28|   2018|    11|  Northeast|     1124|        2|  626|INTIMATE PARTNER ...| 0400 0416 1814 2000|     34|      F|Hispanic/Latin/Me...|     501|SINGLE FAMILY DWE...|STRONG-ARM (HANDS...|    AO| Adult Other| 34.1186| -118.245|   3200 W AVENUE 32 |  Evening|\n",
      "|2020-02-22|2020-02-22|   1900|     5|     Harbor|      511|        1|  440|THEFT PLAIN - PET...|0319 0344 0429 04...|     29|      F|               White|     102|            SIDEWALK|STRONG-ARM (HANDS...|    IC| Invest Cont| 33.7926|-118.3043|PACIFIC COAST VER...|  Evening|\n",
      "|2021-11-22|2020-11-19|   1200|     9|   Van Nuys|      932|        2|  354|   THEFT OF IDENTITY|           1501 1822|     46|      M|               Black|     502|MULTI-UNIT DWELLI...|      NO WEAPON INFO|    IC| Invest Cont| 34.1857|-118.4574|     14700 FRIAR ST |Afternoon|\n",
      "|2020-01-14|2020-01-14|   1330|     1|    Central|      152|        1|  210|             ROBBERY|0416 0411 0344 18...|     66|      M|               Black|     103|               ALLEY|       FOLDING KNIFE|    IC| Invest Cont| 34.0463| -118.255|            7TH HILL|Afternoon|\n",
      "|2020-09-10|2020-09-09|   1735|     9|   Van Nuys|      909|        2|  354|   THEFT OF IDENTITY|      0377 1822 0928|     40|      M|               Other|     507|CONDOMINIUM/TOWNH...|      NO WEAPON INFO|    IC| Invest Cont| 34.2039|-118.4312|  13600 LEADWELL ST |  Evening|\n",
      "|2020-01-14|2020-01-14|   1730|     1|    Central|      162|        1|  341|THEFT-GRAND ($950...|      0344 1822 2032|     31|      M|Hispanic/Latin/Me...|     404|    DEPARTMENT STORE|      NO WEAPON INFO|    IC| Invest Cont|  34.048|-118.2577|       700 W 7TH ST |  Evening|\n",
      "|2020-01-15|2020-01-15|   1445|     1|    Central|      162|        1|  442|SHOPLIFTING - PET...|      0325 1402 0907|     27|      M|               Black|     404|    DEPARTMENT STORE|      NO WEAPON INFO|    IC| Invest Cont|  34.048|-118.2577|       700 W 7TH ST |Afternoon|\n",
      "|2021-11-18|2020-12-28|      1|    10|West Valley|     1045|        2|  354|   THEFT OF IDENTITY|      1822 0930 0929|     46|      F|               White|     501|SINGLE FAMILY DWE...|      NO WEAPON INFO|    IC| Invest Cont| 34.1748|-118.5228|    5700 ENFIELD AV |    Night|\n",
      "|2020-01-15|2020-01-15|    700|     1|    Central|      166|        1|  230|ASSAULT WITH DEAD...| 0416 0913 2004 1218|     62|      M|         Other Asian|     502|MULTI-UNIT DWELLI...|UNKNOWN WEAPON/OT...|    AO| Adult Other| 34.0428|-118.2461|  600 SAN JULIAN ST |  Morning|\n",
      "+----------+----------+-------+------+-----------+---------+---------+-----+--------------------+--------------------+-------+-------+--------------------+--------+--------------------+--------------------+------+------------+--------+---------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define conditions for the new TimeOfDay column\n",
    "conditions = [\n",
    "    (col('TimeOcc').between(500, 1159), 'Morning'),\n",
    "    (col('TimeOcc').between(1200, 1659), 'Afternoon'),\n",
    "    (col('TimeOcc').between(1700, 2059), 'Evening'),\n",
    "    (col('TimeOcc').between(2100, 2400) | col('TimeOcc').between(0, 459), 'Night')\n",
    "]\n",
    "\n",
    "# Apply conditions to create the new column TimeOfDay\n",
    "df_spark = df_spark.withColumn(\n",
    "    'TimeOfDay',\n",
    "    when(conditions[0][0], conditions[0][1])\n",
    "    .when(conditions[1][0], conditions[1][1])\n",
    "    .when(conditions[2][0], conditions[2][1])\n",
    "    .when(conditions[3][0], conditions[3][1])\n",
    "    .otherwise(col('TimeOcc'))\n",
    ")\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nq0pxvL8Mjgd",
    "outputId": "1c4bb7be-7ea8-43ac-bb97-8006963ebec2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/27 15:12:49 ERROR Executor: Exception in task 0.0 in stage 11.0 (TID 25)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/adit0106/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1100, in main\n",
      "    raise PySparkRuntimeError(\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 11) than that in driver 3.9, PySpark cannot run with different minor versions.\n",
      "Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "23/11/27 15:12:49 WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 25) (10.0.0.237 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/adit0106/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1100, in main\n",
      "    raise PySparkRuntimeError(\n",
      "pyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 11) than that in driver 3.9, PySpark cannot run with different minor versions.\n",
      "Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:572)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:94)\n",
      "\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:75)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:525)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:43)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:388)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1623)\n",
      "\n",
      "23/11/27 15:12:49 ERROR TaskSetManager: Task 0 in stage 11.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/Users/adit0106/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1100, in main\n    raise PySparkRuntimeError(\npyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 11) than that in driver 3.9, PySpark cannot run with different minor versions.\nPlease check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r1/vlttm_4125s0n8m6ztz_hwrm0000gn/T/ipykernel_42990/1536386316.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Show the updated DataFrame with new columns 'Year' and 'Month'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/Users/adit0106/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 1100, in main\n    raise PySparkRuntimeError(\npyspark.errors.exceptions.base.PySparkRuntimeError: [PYTHON_VERSION_MISMATCH] Python in worker has different version (3, 11) than that in driver 3.9, PySpark cannot run with different minor versions.\nPlease check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, udf\n",
    "from calendar import month_name\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Assuming 'DateOcc' is in the correct date format\n",
    "df_spark = df_spark.withColumn('Year', year('DateOcc'))\n",
    "\n",
    "# Create a User Defined Function (UDF) to convert month number to month name\n",
    "def get_month_name(month_num):\n",
    "    return month_name[month_num]\n",
    "\n",
    "month_name_udf = udf(get_month_name, StringType())\n",
    "\n",
    "# Add a new column 'Month' with the name of the month\n",
    "df_spark = df_spark.withColumn('Month', month_name_udf(month('DateOcc')))\n",
    "\n",
    "# Show the updated DataFrame with new columns 'Year' and 'Month'\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUOnyu9tHyLn"
   },
   "source": [
    "## dropping unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gj7AGoEDHj6-",
    "outputId": "2e07b97b-e6c9-43ae-80c0-c07e629dacc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+---------+-------+----+-------+-----------+\n",
      "|           CrmCdDesc|CrimeType|TimeOfDay|TimeOcc|Year|  Month|   AreaName|\n",
      "+--------------------+---------+---------+-------+----+-------+-----------+\n",
      "|BATTERY - SIMPLE ...|        2|    Night|   2230|2020|January|  Southwest|\n",
      "|BATTERY - SIMPLE ...|        2|    Night|    330|2020|January|    Central|\n",
      "|VANDALISM - MISDE...|        2|  Evening|   1730|2020|January|N Hollywood|\n",
      "+--------------------+---------+---------+-------+----+-------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns to drop\n",
    "columns_to_keep = ['CrmCdDesc', 'CrimeType', 'TimeOfDay', 'TimeOcc', 'Year', 'Month', 'AreaName']\n",
    "df_spark = df_spark.select(*columns_to_keep)\n",
    "df_spark.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03aizyroUPxg"
   },
   "source": [
    "## Pushing to postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3PzXekOIUEhu"
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Aditya\n",
    "conn = psycopg2.connect(\n",
    "    host = 'localhost',\n",
    "    dbname = 'cs777',\n",
    "    user = 'postgres',\n",
    "    password = 'IronMan@0132',\n",
    "    port = 5432\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glFdJjkaUWc5"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "connection_str = 'postgresql://postgres:IronMan%400132@localhost:5432/cs777'\n",
    "engine = create_engine(connection_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DWynxfzUXNo"
   },
   "outputs": [],
   "source": [
    "df_spark.to_sql('demographic', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
